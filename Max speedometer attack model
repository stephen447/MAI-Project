import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers
from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D, LeakyReLU
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score
import sklearn as skl
import sklearn.model_selection
from sklearn.model_selection import train_test_split
from sklearn.dummy import DummyRegressor
from sklearn.utils import shuffle
import matplotlib.pyplot as plt
plt.rc('font', size=18)
plt.rcParams['figure.constrained_layout.use'] = True
import pandas as p
import sys
import ssl
import time
import sklearn.metrics as metrics
from sklearn.metrics import roc_curve
import matplotlib.patches as mpatches

start_time = time.time()
ssl._create_default_https_context = ssl._create_unverified_context

df = p.read_csv('/Users/stephenbyrne/Documents/College Year 5/Project/Attacks/max_speedometer_attack_1.csv')
c1 = df.iloc[:, 2]  # Reading in ID

ID = [None]*len(c1)
PL = [None]*len(c1)
TV = [None]*len(c1)

y = 0; z = 0

for i in range(0, len(c1)):  # splitting id in HEX form
    string = c1[i]
    ID[i] = string[0:3]
    PL[i] = string[4:20]

for i in range(len(c1)):
	if c1[i][14:16] == "FF":
		if c1[i][0:3] == '0D0':
			TV[i] = 1
			y = y + 1
	else:
		TV[i] = 0
		z = z + 1



print('No. of attacks', y)
print('No. of safe messages', z)

PL1 = [None] * len(PL)  # Separated payload 1
PL2 = [None] * len(PL)  # Separated payload 2
PL3 = [None] * len(PL)  # Separated payload 3
PL4 = [None] * len(PL)  # Separated payload 4
PLbin = [None] * len(PL)  # Separated payload 4
pl = 0; pl1 = 0; pl2 = 0; pl3 = 0; pl4 = 0;
ID1 = [None] * len(ID)  # Separated payload 1
ID2 = [None] * len(ID)  # Separated payload 2
ID3 = [None] * len(ID)  # Separated payload 3
IDbin = [None] * len(ID)  # Separated payload 3
IDcomb = [None] * len(ID)  # Separated payload 3

for i in range(0, len(PL)):
	pl = PL[i]
	pl = int(pl, 16)
	pl = bin(pl)
	pl = pl[2:]
	PLbin[i] = pl.zfill(64)
	PL1[i] = PLbin[i][2:18]
	PL2[i] = PLbin[i][18:34]
	PL3[i] = PLbin[i][34:50]
	PL4[i] = PLbin[i][50:66]


for i in range(0, len(PL1)):
	pl1 = PL1[i]
	pl2 = PL2[i]
	pl3 = PL3[i]
	pl4 = PL4[i]
	PL1[i] = int(pl1, 2)
	PL2[i] = int(pl2, 2)
	PL3[i] = int(pl3, 2)
	PL4[i] = int(pl4, 2)

for i in range(0, len(ID)):
    id = ID[i]
    id = int(id, 16)
    id = bin(id)
    id = id[2:]
    id = id.zfill(12)
    IDbin[i] = id

for i in range(3, len(ID)):
	ID1[i] = IDbin[i - 1]
	ID2[i] = IDbin[i - 2]
	ID3[i] = IDbin[i - 3]
	IDcomb[i] = IDbin[i] + ID1[i] + ID2[i] + ID3[i]
	IDcomb[i] = int(IDcomb[i], 2)

df['Target Variable'] = TV
df['Combined IDs'] = IDcomb
df['PL 1'] = PL1
df['PL 2'] = PL2
df['PL 3'] = PL3
df['PL 4'] = PL4

print(df)
df = df.iloc[3:]
print(df)


x = df.iloc[:, 4:9]  # Reading in first feature
y = df.iloc[:, 3]  # Reading in target

# Model / data parameters
num_classes = 1
input_shape = (5, 1, 1)


x_train, x_test, y_train, y_test = skl.model_selection.train_test_split(x, y, test_size=.1, random_state=0)  # Splitting data into training and test
print("orig x_train shape:", x_train.shape)
print("length of testing", len(x_test))
print("length of training", len(x_train))
print("x train", x_train)
print("y_train", y_train)

x_train = x_train.values.reshape(len(x_train), 5, 1, 1)
x_test = x_test.values.reshape(len(x_test), 5, 1, 1)
y_train = y_train.values.reshape(len(y_train), 1)
y_test = y_test.values.reshape(len(y_test), 1)

use_saved_model = False
if use_saved_model:
	model = keras.models.load_model("cifar.model")
else:
	model = keras.Sequential()
	#model.add(Conv2D(16, (3,3), padding='same', input_shape=x_train.shape[1:],activation='relu'))
	model.add(Conv2D(16, (3, 3), padding='same', input_shape=input_shape, activation='relu'))
	#model.add(Conv2D(16, (3,3), strides=(2, 2), padding='same', activation='relu'))
	model.add(Conv2D(16, (3,3), padding='same', activation='relu'))
	#model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Conv2D(32, (3,3), padding='same', activation='relu'))
	#model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', activation='relu'))
	model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))
	#model.add(MaxPooling2D(pool_size=(2, 2)))
	#model.add(Dropout(0.5))
	model.add(Flatten())
	model.add(Dense(num_classes, activation='sigmoid',kernel_regularizer=regularizers.l1(0.0001)))
	#model.compile(loss="sparse_categorical_crossentropy", optimizer='adam', metrics=["accuracy"])
	model.compile(loss="binary_crossentropy", optimizer='adam', metrics=["accuracy"])
	model.summary()

	batch_size = 128
	epochs = 20
	history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)
	model.save("cifar.model")
	print("--- %s seconds ---" % (time.time() - start_time))
	plt.subplot(211)
	plt.plot(history.history['accuracy'])
	plt.plot(history.history['val_accuracy'])
	plt.title('model accuracy')
	plt.ylabel('accuracy')
	plt.xlabel('epoch')
	plt.legend(['train', 'val'], loc='upper left')
	plt.subplot(212)
	plt.plot(history.history['loss'])
	plt.plot(history.history['val_loss'])
	plt.title('model loss')
	plt.ylabel('loss'); plt.xlabel('epoch')
	plt.legend(['train', 'val'], loc='upper left')
	plt.show()

# Classifying data
np.set_printoptions(threshold=sys.maxsize)
preds = model.predict(x_test)
print('Predictions', preds)
for i in range(len(preds)):
	if(preds[i]>.1):
		print(preds[i], '\n', i)
		preds[i] = 1
	else:
		preds[i] = 0


# Performance metrics
#print("X test", x_test)
#print("y test", y_test)
print("predictions", preds)
print(classification_report(y_test, preds))
print(confusion_matrix(y_test,preds))
#print("Accuracy (Baseline):  ", model.score(t, BL_pred))  # Accuracy
print("F1 score: ", f1_score(y_test, preds, average="macro"))  # F1 score
print("Precision: ", precision_score(y_test, preds, average="macro"))  # Precision score
print("Recall: ", recall_score(y_test, preds, average="macro"))  # Recall score

# ROC curve
plt.figure('ROC curve')
fpr, tpr, _ = roc_curve(y_test, preds)  # Defining false positives and true positives
plt.title("ROC curve for NN") # Title
plt.plot(fpr,tpr, c='blue')  # Plot roc curve
plt.xlabel('False positive rate')  # X label
plt.ylabel('True positive rate')  # Y label
#plt.show()

# Calculate the fpr and tpr for all thresholds of the classification
probs = model.predict(x_test)
predicts = probs[:,0]
fpr, tpr, threshold = roc_curve(y_test, predicts)  # Knn fpr and tpr
roc_auc = metrics.auc(fpr, tpr)
plt.plot(fpr, tpr, c='orange')  # Plot roc curve

NN = mpatches.Patch(color = 'green', label="LR")  # Legend for NN
plt.legend(handles=[NN], loc="center right")  # Plotting legend
fpr, tpr, thresholds = roc_curve(y_test, preds)  # ROC curve
plt.plot(fpr, tpr, c='green')  # Plot ROC curve
plt.show()
